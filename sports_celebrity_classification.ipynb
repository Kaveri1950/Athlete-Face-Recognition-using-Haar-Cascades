{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "1eHf6ohNT3cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pywt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DbsbziJXrfFF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Haar Cascade Classifiers"
      ],
      "metadata": {
        "id": "8L7iNDi9T_jf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cchuv8oitz1d"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/opencv/haarcascades/haarcascade_eye.xml')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wavelet Transform Function"
      ],
      "metadata": {
        "id": "kAVlnriWUJcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lBNZR2Kztz1d"
      },
      "outputs": [],
      "source": [
        "def w2d(img, mode='haar', level=1):\n",
        "    imArray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    imArray = np.float32(imArray)\n",
        "    imArray /= 255\n",
        "    coeffs = pywt.wavedec2(imArray, mode, level=level)\n",
        "    coeffs_H = list(coeffs)\n",
        "    coeffs_H[0] *= 0\n",
        "    imArray_H = pywt.waverec2(coeffs_H, mode)\n",
        "    imArray_H *= 255\n",
        "    imArray_H = np.uint8(imArray_H)\n",
        "    return imArray_H"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face and Eye Detector"
      ],
      "metadata": {
        "id": "o3CRnn1lUOOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t5H6oBG5tz1f"
      },
      "outputs": [],
      "source": [
        "def get_cropped_image_if_2_eyes(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi_gray = gray[y:y + h, x:x + w]\n",
        "        roi_color = img[y:y + h, x:x + w]\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        if len(eyes) >= 2:\n",
        "            return roi_color\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Crop and Save Valid Face Images\n"
      ],
      "metadata": {
        "id": "Z3TxRARWUYzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ep1UHXfHtz1h"
      },
      "outputs": [],
      "source": [
        "path_to_data = \"/content/drive/MyDrive/celebrity_dataset_final\"\n",
        "path_to_cr_data = os.path.join(path_to_data, \"cropped\")\n",
        "\n",
        "#Collect image directories\n",
        "img_dirs = [entry.path for entry in os.scandir(path_to_data) if entry.is_dir()]\n",
        "\n",
        "#Clear cropped directory if it exists\n",
        "import shutil\n",
        "if os.path.exists(path_to_cr_data):\n",
        "    shutil.rmtree(path_to_cr_data)\n",
        "os.makedirs(path_to_cr_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzaBvEKrtz1i",
        "outputId": "3e379b01-8528-49e0-e4d6-3f9a0f390bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Allyson_Felix_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Anthony_Davis_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Antoine_Griezmann_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Aryna_Sabalenka_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Babar_Azam_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Ben_Stokes_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Carlos_Alcaraz_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/chris evans - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Carl_Lewis_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/chris hemsworth - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Coco_Gauff_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Cristiano_Ronaldo_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Daniil_Medvedev_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Elaine_Thompson-Herah_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Florence_Griffith-Joyner_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Hardik_Pandya_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Harry_Kane_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Erling_Haaland_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Giannis_Antetokounmpo_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Iga_Świątek_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/James_Harden_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Jannik_Sinner_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Jayson_Tatum_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Jasprit_Bumrah_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/jennifer lawrence - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Joe_Root_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Kane_Williamson_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Karim_Benzema_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Kevin_Durant_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Kylian_Mbappé_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/KL_Rahul_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/LeBron_James_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Kyrie_Irving_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Lionel_Messi_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Luka_Modrić_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Mohamed_Salah_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Mondo_Duplantis_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/MS_Dhoni_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Naomi_Osaka_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Neeraj_Chopra_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Novak_Djokovic_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Paulo_Dybala_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Neymar_Jr_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Rishabh_Pant_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/robert downey jr - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Rohit_Sharma_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Rafael_Nadal_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Roger_Federer_tennis\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/rose blackpink - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Sachin_Tendulkar_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/scarlett johansson - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/selena gomez - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/shawn mendes - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Shelly-Ann_Fraser-Pryce_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Shubman_Gill_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Son_Heung-min_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Stephen_Curry_basketball\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Steve_Smith_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/tom hiddleston - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/tom holland - Google Search\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Sydney_McLaughlin_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Virgil_van_Dijk_football\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Virat_Kohli_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Usain_Bolt_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Yulimar_Rojas_athletics\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/Yuvraj_Singh_cricket\n",
            " Generating cropped images in folder: /content/drive/MyDrive/celebrity_dataset_final/cropped/zendaya - Google Search\n"
          ]
        }
      ],
      "source": [
        "cropped_image_dirs = []\n",
        "celebrity_file_names_dict = {}\n",
        "\n",
        "for img_dir in img_dirs:\n",
        "    count = 1\n",
        "    celebrity_name = os.path.basename(img_dir)\n",
        "    celebrity_file_names_dict[celebrity_name] = []\n",
        "\n",
        "    for entry in os.scandir(img_dir):\n",
        "        if entry.is_file() and entry.name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
        "\n",
        "            if roi_color is not None:\n",
        "                cropped_folder = os.path.join(path_to_cr_data, celebrity_name)\n",
        "\n",
        "                if not os.path.exists(cropped_folder):\n",
        "                    os.makedirs(cropped_folder)\n",
        "                    cropped_image_dirs.append(cropped_folder)\n",
        "                    print(\" Generating cropped images in folder:\", cropped_folder)\n",
        "\n",
        "                cropped_file_name = f\"{celebrity_name}{count}.png\"\n",
        "                cropped_file_path = os.path.join(cropped_folder, cropped_file_name)\n",
        "\n",
        "                cv2.imwrite(cropped_file_path, roi_color)\n",
        "                celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
        "                count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xIRVj8R_tz1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35731d8-2010-44fc-c84e-570682757ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Verifying files per celebrity:\n",
            "Allyson_Felix_athletics: 19 files\n",
            "Anthony_Davis_basketball: 17 files\n",
            "Antoine_Griezmann_football: 10 files\n",
            "Aryna_Sabalenka_tennis: 25 files\n",
            "Babar_Azam_cricket: 9 files\n",
            "Ben_Stokes_cricket: 5 files\n",
            "Carlos_Alcaraz_tennis: 15 files\n",
            "chris evans - Google Search: 48 files\n",
            "Carl_Lewis_athletics: 6 files\n",
            "chris hemsworth - Google Search: 38 files\n",
            "Coco_Gauff_tennis: 10 files\n",
            "Cristiano_Ronaldo_football: 32 files\n",
            "Daniil_Medvedev_tennis: 17 files\n",
            "Elaine_Thompson-Herah_athletics: 18 files\n",
            "Florence_Griffith-Joyner_athletics: 9 files\n",
            "Hardik_Pandya_cricket: 20 files\n",
            "Harry_Kane_football: 31 files\n",
            "Erling_Haaland_football: 16 files\n",
            "Giannis_Antetokounmpo_basketball: 27 files\n",
            "Iga_Świątek_tennis: 3 files\n",
            "James_Harden_basketball: 10 files\n",
            "Jannik_Sinner_tennis: 18 files\n",
            "Jayson_Tatum_basketball: 26 files\n",
            "Jasprit_Bumrah_cricket: 16 files\n",
            "jennifer lawrence - Google Search: 17 files\n",
            "Joe_Root_cricket: 12 files\n",
            "Kane_Williamson_cricket: 10 files\n",
            "Karim_Benzema_football: 14 files\n",
            "Kevin_Durant_basketball: 12 files\n",
            "Kevin_De_Bruyne_football: 0 files\n",
            "Kylian_Mbappé_football: 19 files\n",
            "KL_Rahul_cricket: 21 files\n",
            "LeBron_James_basketball: 23 files\n",
            "Kyrie_Irving_basketball: 9 files\n",
            "Lionel_Messi_football: 21 files\n",
            "Luka_Dončić_basketball: 0 files\n",
            "Luka_Modrić_football: 21 files\n",
            "Mohamed_Salah_football: 16 files\n",
            "Mondo_Duplantis_athletics: 17 files\n",
            "MS_Dhoni_cricket: 13 files\n",
            "Naomi_Osaka_tennis: 11 files\n",
            "Neeraj_Chopra_athletics: 18 files\n",
            "Novak_Djokovic_tennis: 15 files\n",
            "Paulo_Dybala_football: 19 files\n",
            "Neymar_Jr_football: 14 files\n",
            "Rishabh_Pant_cricket: 13 files\n",
            "robert downey jr - Google Search: 21 files\n",
            "Rohit_Sharma_cricket: 13 files\n",
            "Rafael_Nadal_tennis: 13 files\n",
            "Roger_Federer_tennis: 13 files\n",
            "rose blackpink - Google Search: 55 files\n",
            "Sachin_Tendulkar_cricket: 12 files\n",
            "scarlett johansson - Google Search: 38 files\n",
            "selena gomez - Google Search: 39 files\n",
            "shawn mendes - Google Search: 27 files\n",
            "Shelly-Ann_Fraser-Pryce_athletics: 9 files\n",
            "Shubman_Gill_cricket: 8 files\n",
            "Son_Heung-min_football: 17 files\n",
            "Stephen_Curry_basketball: 19 files\n",
            "Steve_Smith_cricket: 3 files\n",
            "tom hiddleston - Google Search: 59 files\n",
            "tom holland - Google Search: 10 files\n",
            "Sydney_McLaughlin_athletics: 28 files\n",
            "Virgil_van_Dijk_football: 16 files\n",
            "Virat_Kohli_cricket: 13 files\n",
            "Usain_Bolt_athletics: 1 files\n",
            "Yulimar_Rojas_athletics: 14 files\n",
            "Yuvraj_Singh_cricket: 13 files\n",
            "zendaya - Google Search: 12 files\n",
            "cropped: 0 files\n"
          ]
        }
      ],
      "source": [
        "#Check loaded file lists from cropped folders\n",
        "print(\"\\n Verifying files per celebrity:\")\n",
        "for celeb, files in celebrity_file_names_dict.items():\n",
        "    print(f\"{celeb}: {len(files)} files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q0ZTcTpztz1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d09d8c0-408f-4ad4-a9ce-04e086aa441e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After filtering, 3 classes kept out of 70\n"
          ]
        }
      ],
      "source": [
        "# Filter out classes with fewer than N(min_images) images\n",
        "min_images = 40\n",
        "filtered_celebrity_file_names_dict = {\n",
        "    celeb: files\n",
        "    for celeb, files in celebrity_file_names_dict.items()\n",
        "    if len(files) >= min_images\n",
        "}\n",
        "\n",
        "print(f\"\\nAfter filtering, {len(filtered_celebrity_file_names_dict)} classes kept out of {len(celebrity_file_names_dict)}\")\n",
        "\n",
        "# Update downstream variables\n",
        "celebrity_file_names_dict = filtered_celebrity_file_names_dict\n",
        "class_dict = {name: idx for idx, name in enumerate(celebrity_file_names_dict.keys())}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9X-8o7NLtz1m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Feature Matrix (X) and Labels (y)\n",
        "X, y = [], []\n",
        "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
        "    for training_image in training_files:\n",
        "        img = cv2.imread(training_image)\n",
        "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
        "        img_har = w2d(img, 'db1', 5)\n",
        "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
        "        combined_img = np.vstack((\n",
        "            scalled_raw_img.reshape(32 * 32 * 3, 1),\n",
        "            scalled_img_har.reshape(32 * 32, 1)\n",
        "        ))\n",
        "        X.append(combined_img)\n",
        "        y.append(class_dict[celebrity_name])\n",
        "\n",
        "X = np.array(X).reshape(len(X), 4096).astype(float)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9-bWX2IItz1n"
      },
      "outputs": [],
      "source": [
        "# Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test different Models"
      ],
      "metadata": {
        "id": "DudhC21DUeec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV for Best Model"
      ],
      "metadata": {
        "id": "2_Ef5z04UrSO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SSwZH53htz1o"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "    'svm': {\n",
        "        'model': svm.SVC(gamma='auto', probability=True),\n",
        "        'params': {\n",
        "            'svc__C': [1, 10, 100],\n",
        "            'svc__kernel': ['rbf', 'linear']\n",
        "        }\n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params': {\n",
        "            'randomforestclassifier__n_estimators': [5, 10]\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression': {\n",
        "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
        "        'params': {\n",
        "            'logisticregression__C': [1, 5, 10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoV0LtIYtz1q",
        "outputId": "8ab09cda-51aa-48cf-b965-52d5b3bfb38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model Comparison:\n",
            "                  model  best_score  \\\n",
            "0                  svm    0.843333   \n",
            "1        random_forest    0.695333   \n",
            "2  logistic_regression    0.860333   \n",
            "\n",
            "                                    best_params  \n",
            "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
            "1  {'randomforestclassifier__n_estimators': 10}  \n",
            "2                  {'logisticregression__C': 1}  \n"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "best_estimators = {}\n",
        "\n",
        "for algo, mp in model_params.items():\n",
        "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
        "    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(X_train, y_train)\n",
        "    scores.append({\n",
        "        'model': algo,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "    best_estimators[algo] = clf.best_estimator_\n",
        "\n",
        "df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
        "print(\"\\n Model Comparison:\\n\", df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV for KNN"
      ],
      "metadata": {
        "id": "YRZcgFugU0_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'knn__n_neighbors': [3, 4, 5,6, 7, 8, 9, 11, 12, 13, 14, 15],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__p': [1, 2]  # 1=Manhattan, 2=Euclidean\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    knn_pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
        "print(f\"Best Cross Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "#FINAL EVALUATION\n",
        "\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_knn.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Test Accuracy: {acc*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3GmI6fsPVir",
        "outputId": "bb98a3b5-4ab7-40da-db30-561de4bc746f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "\n",
            "Best Parameters: {'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'distance'}\n",
            "Best Cross Validation Accuracy: 0.7360\n",
            "\n",
            " Test Accuracy: 70.73%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.45      0.53        11\n",
            "           1       0.79      0.85      0.81        13\n",
            "           2       0.68      0.76      0.72        17\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.70      0.69      0.69        41\n",
            "weighted avg       0.70      0.71      0.70        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBOOST Classifier"
      ],
      "metadata": {
        "id": "ejDu9F8VVD9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# EVALUATE\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Accuracy: {acc*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byh0L5TdA5S8",
        "outputId": "503c9feb-6025-45ae-fa42-72bb780f999b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:14:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy: 78.05%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.55      0.63        11\n",
            "           1       0.79      0.85      0.81        13\n",
            "           2       0.79      0.88      0.83        17\n",
            "\n",
            "    accuracy                           0.78        41\n",
            "   macro avg       0.78      0.76      0.76        41\n",
            "weighted avg       0.78      0.78      0.77        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stack Classifier"
      ],
      "metadata": {
        "id": "-svn7Bp9W0ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('svm', SVC(kernel='rbf', probability=True, C=5)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=150, random_state=42)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5, weights='distance')),\n",
        "    ('xgb', XGBClassifier(\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=4,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='mlogloss'\n",
        "    ))\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# STACKING CLASSIFIER PIPELINE\n",
        "\n",
        "stack_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('stack', StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=meta_model,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    ))\n",
        "])\n",
        "\n",
        "\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# EVALUATION\n",
        "y_pred = stack_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Stacking Model Accuracy: {acc*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHChhHMSLR3",
        "outputId": "b62fc11a-18ee-489f-e433-a2353cd2f109"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Stacking Model Accuracy: 82.93%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.74        11\n",
            "           1       0.85      0.85      0.85        13\n",
            "           2       0.80      0.94      0.86        17\n",
            "\n",
            "    accuracy                           0.83        41\n",
            "   macro avg       0.84      0.81      0.82        41\n",
            "weighted avg       0.83      0.83      0.82        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV + Stack Classifier\n"
      ],
      "metadata": {
        "id": "0oAyiccdX8Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning SVM\n",
        "svm_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(probability=True))\n",
        "])\n",
        "svm_params = {'svm__C': [1, 5, 10], 'svm__kernel': ['linear', 'rbf']}\n",
        "svm_grid = GridSearchCV(svm_pipe, svm_params, cv=3, n_jobs=-1, verbose=1)\n",
        "svm_grid.fit(X_train, y_train)\n",
        "svm_best = svm_grid.best_estimator_\n",
        "print(\" Best SVM:\", svm_grid.best_params_)\n",
        "#Tuning KNN\n",
        "knn_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "knn_params = {'knn__n_neighbors': [3, 5, 7], 'knn__weights': ['uniform', 'distance']}\n",
        "knn_grid = GridSearchCV(knn_pipe, knn_params, cv=3, n_jobs=-1, verbose=1)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "knn_best = knn_grid.best_estimator_\n",
        "print(\" Best KNN:\", knn_grid.best_params_)\n",
        "\n",
        "# Tuning RandomForest\n",
        "rf_grid = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    {'n_estimators': [100, 150], 'max_depth': [None, 10, 20]},\n",
        "    cv=3, n_jobs=-1, verbose=1\n",
        ")\n",
        "rf_grid.fit(X_train, y_train)\n",
        "rf_best = rf_grid.best_estimator_\n",
        "print(\" Best RF:\", rf_grid.best_params_)\n",
        "\n",
        "# Tuning XGBoost\n",
        "xgb_grid = GridSearchCV(\n",
        "    XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    {'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.05, 0.1]},\n",
        "    cv=3, n_jobs=-1, verbose=1\n",
        ")\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "xgb_best = xgb_grid.best_estimator_\n",
        "print(\" Best XGB:\", xgb_grid.best_params_)\n",
        "\n",
        "\n",
        "# STACKING CLASSIFIER\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_best),\n",
        "        ('rf', rf_best),\n",
        "        ('knn', knn_best),\n",
        "        ('xgb', xgb_best)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Training final stacking model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# EVALUATE\n",
        "y_pred = stack_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Final Stacking Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# SAVE MODEL\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "joblib.dump(stack_model, \"models/stacking_tuned_model.pkl\")\n",
        "joblib.dump(class_dict, \"models/class_dict.pkl\")\n",
        "print(\"\\n Saved final stacked model with tuned base learners.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6HVhgheTdJw",
        "outputId": "e56455bd-49de-4839-ba15-ac8e4879c0a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            " Best SVM: {'svm__C': 1, 'svm__kernel': 'linear'}\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            " Best KNN: {'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            " Best RF: {'max_depth': None, 'n_estimators': 150}\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:19:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best XGB: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
            "\n",
            " Final Stacking Accuracy: 87.80%\n",
            "\n",
            " Saved final stacked model with tuned base learners.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}